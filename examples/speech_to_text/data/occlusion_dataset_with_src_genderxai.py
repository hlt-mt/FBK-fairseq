# Copyright 2024 FBK

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License

from typing import List, Tuple, Dict, Union
import logging

import torch
from torch import Tensor

from examples.speech_to_text.data.occlusion_dataset import OccludedSpeechToTextDataset
from fairseq.data.audio.speech_to_text_dataset import _collate_frames
from fairseq.data import data_utils


LOGGER = logging.getLogger(__name__)


class OccludedSpeechToTextDatasetWithSrcGenderXai(OccludedSpeechToTextDataset):
    """
    Adapts the OccludedSpeechToTextDataset class so samples contain information about the position 
    and correct and incorrect forms of gender terms as well as a version of the target text with 
    the gender swapped.
    This class is meant to be used when occluding a dataset with source texts,
    typically, SpeechToTextDatasetWithSrcGenderXai.
    """

    def __getitem__(self, perturb_index: int) -> Tuple[
        int, int, Tensor, Tensor, Tensor, Union[Tensor, None], List[str], List[str], List[int], List[str], List[str], Tensor]:
        
        orig_dataset_index = self._original_index(perturb_index)
        returned_tuple = self.dataset[orig_dataset_index]
        
        index, fbank, predicted_tokens, source_text, tgt_text, found_terms, found_term_pairs, \
            gender_terms_indices, swapped_tgt_texts, swapped_tgt_tokens, *_ = returned_tuple
        
        mask, perturbed_fbank = self.perturbator(fbank, orig_dataset_index, perturb_index)
        
        return (
            perturb_index,
            orig_dataset_index,
            mask,
            perturbed_fbank,
            predicted_tokens,
            source_text,
            tgt_text,
            found_terms,
            found_term_pairs,
            gender_terms_indices,
            swapped_tgt_texts,
            swapped_tgt_tokens)


    def collater(
            self,
            samples: List[Tuple[
                int, int, Tensor, Tensor, Tensor, Union[Tensor, None], List[str], List[str], List[str], List[int], List[str], Tensor]]) -> Dict:
        if len(samples) == 0:
            return {}
        perturb_indices = torch.tensor([i for i, _, _, _, _, _, _, _, _, _, _, _ in samples], dtype=torch.long)
        orig_indices = torch.tensor([i for _, i, _, _, _, _, _, _, _, _, _, _ in samples], dtype=torch.long)
        masks = _collate_frames([m for _, _, m, _, _, _, _, _, _, _, _, _ in samples])
        frames = _collate_frames([s for _, _, _, s, _, _, _, _, _, _, _, _ in samples])
        n_frames = torch.tensor([s.size(0) for _, _, _, s, _, _, _, _, _, _, _, _ in samples], dtype=torch.long)
        n_frames, order = n_frames.sort(descending=True)
        perturb_indices = perturb_indices.index_select(0, order)
        orig_indices = orig_indices.index_select(0, order)
        frames = frames.index_select(0, order)
        masks = masks.index_select(0, order)
        
        # In this class, the target corresponds to the hypothesis previously generated by the model,
        # not to the reference translation/transcript.
        target = data_utils.collate_tokens(
            [p for _, _, _, _, p, _, _, _, _, _, _, _ in samples],
            self.tgt_dict.pad(),
            self.tgt_dict.eos(),
            left_pad=False,
            move_eos_to_beginning=False,
        )
        target = target.index_select(0, order)
        target_lengths = torch.tensor(
            [p.size(0) for _, _, _, _, p, _, _, _, _, _, _, _ in samples], dtype=torch.long
        ).index_select(0, order)

        # In this class, the previous output tokens correspond to the hypothesis previously generated by the model
        prev_output_tokens = data_utils.collate_tokens(
            [p for _, _, _, _, p, _, _, _, _, _, _, _ in samples],
            self.tgt_dict.pad(),
            self.tgt_dict.eos(),
            left_pad=False,
            move_eos_to_beginning=True,
        )
        prev_output_tokens = prev_output_tokens.index_select(0, order)
        
        src_texts = [s for _, _, _, _, _, s, _, _, _, _, _, _ in samples]
        src_texts = [src_texts[i] for i in order]
        tgt_texts = [t for _, _, _, _, _, _, t, _, _, _, _, _ in samples]
        tgt_texts = [tgt_texts[i] for i in order]
        found_terms = [ft for _, _, _, _, _, _, _, ft, _, _, _, _ in samples]
        found_terms = [found_terms[i] for i in order]
        found_term_pairs = [ftp for _, _, _, _, _, _, _, _, ftp, _, _, _ in samples]
        found_term_pairs = [found_term_pairs[i] for i in order]
        gender_terms_indices = [gti for _, _, _, _, _, _, _, _, _, gti, _, _ in samples]
        gender_terms_indices = [gender_terms_indices[i] for i in order]
        swapped_tgt_texts = [st for _, _, _, _, _, _, _, _, _, _, st, _ in samples]
        swapped_tgt_texts = [swapped_tgt_texts[i] for i in order]
        
        swapped_tgt_tokens = data_utils.collate_tokens(
            [stt for _, _, _, _, _, _, _, _, _, _, _, stt in samples],
            self.tgt_dict.pad(),
            self.tgt_dict.eos(),
            left_pad=False,
            move_eos_to_beginning=False)
        swapped_tgt_tokens = swapped_tgt_tokens.index_select(0, order)
        swapped_tgt_lengths = torch.tensor(
                [stt.size(0) for  _, _, _, _, _, _, _, _, _, _, _, stt in samples], dtype=torch.long
            ).index_select(0, order)
        swapped_prev_output_tokens = data_utils.collate_tokens(
            [stt for _, _, _, _, _, _, _, _, _, _, _, stt in samples],
            self.tgt_dict.pad(),
            self.tgt_dict.eos(),
            left_pad=False,
            move_eos_to_beginning=True)
        swapped_prev_output_tokens = swapped_prev_output_tokens.index_select(0, order)

        out = {
            "id": perturb_indices,
            "orig_id": orig_indices,
            "net_input": {
                "src_tokens": frames,
                "src_lengths": n_frames,
                "prev_output_tokens": prev_output_tokens,
                "swapped_prev_output_tokens": swapped_prev_output_tokens},
            "target": target,
            "target_lengths": target_lengths,
            "swapped_target": swapped_tgt_tokens,
            "swapped_target_lengths": swapped_tgt_lengths,
            "masks": masks,
            "src_texts": src_texts,
            "nsentences": len(samples),
            "tgt_texts": tgt_texts,
            "found_terms": found_terms,
            "found_term_pairs": found_term_pairs,
            "gender_terms_indices": gender_terms_indices,
            "swapped_tgt_texts": swapped_tgt_texts,
        }
        return out
