#!/usr/bin/env python3 -u
# Copyright 2024 FBK

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License

import argparse
from typing import Tuple
import pandas as pd
import sentencepiece as spm


OUTPUT_COLUMNS = [
    'id',
    'audio',
    'n_frames',
    'src_text',
    'tgt_text',
    'speaker',
    'found_terms',
    'found_term_pairs',
    'gender_terms_indices',
    'swapped_tgt_text']


def bpe_to_moses(bpe_text: str, sp: spm.SentencePieceProcessor) -> str:
    """
    Args:
        bpe_text: text tokenized with BPE.
        sp: a sentencepiece model used for BPE tokenization.
    Returns:
        The text tokenized with Moses.
    """
    # Get rid of BPE tokenization
    untokenized_hyp = sp.decode(bpe_text.lower().split())
    # Tokenize with moses
    from sacremoses import MosesTokenizer
    mt = MosesTokenizer()
    tokenized_hyp = mt.tokenize(untokenized_hyp, return_str=True)
    return tokenized_hyp


def filter_gender_terms(df_row: pd.Series) -> str:
    """
    Args:
        df_row: a row of the dataframe containing the hypotheses tokenized with moses
                (field 'moses_tgt_text') and the gender terms which should be present 
                according to MuST-SHE annotations (field 'gender_terms').
    Returns:
        - The gender terms present in the hypothesis separated by semicolons.
        - The gender term pairs present in the hypothesis separated by semicolons (the correct term
         followed by the term equivalent in the opposite gender, as annotated in MuST-SHE).
    """
    tokenized_hyp = df_row['moses_tgt_text'].split()
    # Look for the terms in the lower case, tokenized hypothesis 
    # (without matching the same occurrence twice).
    gender_terms = df_row['gender_terms'].split(';')
    found_terms = []
    found_term_pairs = []
    for pair in gender_terms:
        correct_term, wrong_term = pair.split()
        found_correct, found_wrong = False, False
        if correct_term.lower() in tokenized_hyp:
            pos_found = tokenized_hyp.index(correct_term.lower())
            del tokenized_hyp[pos_found]
            found_correct = True
        if wrong_term.lower() in tokenized_hyp:
            pos_found = tokenized_hyp.index(wrong_term.lower())
            del tokenized_hyp[pos_found]
            found_wrong = True
        # If both the correct and wrong terms are found, we do not include them for our analysis
        # since we cannot determine which one refers to the entity in question.
        if found_correct != found_wrong:  # logical XOR
            if found_correct:
                found_terms.append(correct_term)
            else:
                found_terms.append(wrong_term)
            found_term_pairs.append(correct_term + ' ' + wrong_term)
    return ';'.join(found_terms), ';'.join(found_term_pairs)


def _find_term_indices(hyp: str, gender_term: str) -> Tuple[str, str]:
    """
    Args:
        hyp: The BPE-tokenized hypothesis.
        gender_term: The BPE-tokenized gender terms to find in the hypothesis.
    Returns:
        A string with the start and end indices of the gender term in the hypothesis
        and the hypothesis with the gender term erased to avoid matching it again.
    """
    hyp = hyp.split(' ')
    gender_term = gender_term.split(' ')
    for i, token in enumerate(hyp):
        if token == gender_term[0]:
            j = 1
            while j < len(gender_term) and i+j < len(hyp) and gender_term[j] == hyp[i+j]:
                j += 1 
            if j == len(gender_term):
                for k in range(i, i+j):
                    hyp[k] = '***'
                return f'{i}-{i+j-1}', ' '.join(hyp)
    raise ValueError(f'Could not find "{gender_term}" in "{hyp}"')


def find_terms_bpe(df_row: pd.Series, sp: spm.SentencePieceProcessor) -> str:
    """
    Args:
        df_row: a row of a pandas dataframe containing the fields 'tgt_text' (the BPE-tokenized 
                hypothesis generated by the model) and 'found_terms' (the gender terms
                annotated in MuST-SHE that are present in this hypothesis).
        sp: the sentencepiece model used for BPE tokenization.
    Returns:
        The indices of the BPE tokens in the hypothesis that correspond to the gender terms (ranges
        of integers separated by semicolons).
    """
    found_terms = df_row['found_terms'].split(';')
    hypothesis = df_row['tgt_text'].lower()
    indices = []
    for found_term in found_terms:
        # Get a BPE tokenization of the gender terms.
        found_term_bpe = ' '.join(sp.encode(found_term, out_type=str)).lower()
        # Look for the BPE tokens in the hypothesis.
        if found_term_bpe in hypothesis:
            tok_indices, hypothesis = _find_term_indices(hypothesis, found_term_bpe)
            indices.append(tok_indices)
        else:
            # There are many possible BPE tokenizations for a single string, if the most likely
            # one is not found, try other possibilities.
            for _ in range(50):
                found_term_bpe = ' '.join(
                    sp.encode(found_term, out_type=str, enable_sampling=True, alpha=0.1, nbest_size=-1)).lower()
                if found_term_bpe in hypothesis:
                    tok_indices, hypothesis = _find_term_indices(hypothesis, found_term_bpe)
                    indices.append(tok_indices)
                    break
                # The problem could also be that the term is capitalized in the reference, but 
                # lower case in the hypothesis.
                found_term_bpe_lower = ' '.join(sp.encode(found_term.lower(), out_type=str)).lower()
                if found_term_bpe_lower in hypothesis:
                    tok_indices, hypothesis = _find_term_indices(hypothesis, found_term_bpe_lower)
                    indices.append(tok_indices)
                    break
                # Or viceversa.
                found_term_bpe_upper = ' '.join(
                    sp.encode(found_term[0].upper() + found_term[1:], out_type=str)).lower()
                if found_term_bpe_upper in hypothesis:
                    tok_indices, hypothesis = _find_term_indices(hypothesis, found_term_bpe_upper)
                    indices.append(tok_indices)
                    break
    return ';'.join(indices)


def one_term_per_row(df: pd.DataFrame) -> pd.DataFrame:
    """
    Args:
        df: dataframe with each row duplicated as many types as there are gender terms present 
            in that hypothesis. The dataframe should contain a column 'id' with the id of the MuST-SHE sample,
            a column 'found_terms' with the gender terms present in that row's hypothesis, 
            separated by semicolons, a column 'found_term_pairs' with the pair of correct and wrong 
            terms corresponding to the found terms and a column 'gender_terms_indices' with the indices of the
            BPE tokens in the hypothesis corresponding to the found terms.
    Returns:
        The same dataframe with only one different gender term pair per row (hypotheses stay the 
        same, only the 'gender_terms_indices' and 'found_terms' columns change).
    """
    # Dictionary that maps each hypothesis' ID to the index of the term that should be considered
    # next in the list of gender terms for that hypothesis.
    hyp_id_to_term_index = {}

    # Iterate over the DataFrame rows
    for index, row in df.iterrows():
        hyp_id = row['id']
        # If this is the first time we see this hypothesis, initialize the term index to 0
        if hyp_id not in hyp_id_to_term_index:
            hyp_id_to_term_index[hyp_id] = 0

        found_terms_list = row['found_terms'].split(';')
        found_pairs_list = row['found_term_pairs'].split(';')
        indices_list = row['gender_terms_indices'].split(';')
        assert len(found_terms_list) == len(found_pairs_list) == len(indices_list), \
            f"Row {index} has different number of gender terms, gender pairs and indices"

        # Get the current term index for this hypothesis ID
        current_index = hyp_id_to_term_index[hyp_id]

        # If the current index is out of bounds, skip this row
        if current_index >= len(found_terms_list):
            continue

        # Update this row with the current term, term pair, and indices
        df.at[index, 'found_terms'] = found_terms_list[current_index]
        df.at[index, 'found_term_pairs'] = found_pairs_list[current_index]
        df.at[index, 'gender_terms_indices'] = indices_list[current_index]

        # Increment the term index for this hypothesis ID
        hyp_id_to_term_index[hyp_id] = current_index + 1

    return df


def swap_gender_hypothesis(df_row: pd.Series, sp: spm.SentencePieceProcessor) -> str:
    """
    Args:
        df_row: a row of a pandas dataframe containing the fields 'tgt_text' (the BPE-tokenized 
                hypothesis generated by the model), 'found_terms' (the gender term present 
                in this hypothesis), 'found_term_pairs' (the pair of correct and wrong terms corresponding
                to the found term, in the MuST-SHE annotation format) and 'gender_terms_indices'  
                (the indices of the BPE tokens in the hypothesis that correspond to the gender terms).
        sp: the sentencepiece model used for BPE tokenization.
    Returns:
        The BPE-tokenized hypothesis with the gender of the gender term swapped.
    """
    hypothesis = df_row['tgt_text'].split(' ')
    # If there are no gender terms, leave hypothesis unchanged.
    if df_row['found_terms'] == '' or df_row['found_term_pairs'] == '' \
            or df_row['gender_terms_indices'] == '':
        return ' '.join(hypothesis)
    found_terms = df_row['found_terms'].split(';')
    found_term_pairs = df_row['found_term_pairs'].split(';')
    gt_indices = df_row['gender_terms_indices'].split(';')
    for found_term, term_pair, indices in zip(found_terms, found_term_pairs, gt_indices):
        correct_term, wrong_term = term_pair.split()
        swap_term = correct_term if found_term == wrong_term else wrong_term
        start, end = indices.split('-')
        start, end = int(start), int(end)
        swap_term = sp.encode(swap_term, out_type=str)
        # Replace the elements in the range with the swapped term.
        hypothesis[start:end + 1] = swap_term 
    return ' '.join(hypothesis)


def main(args: argparse.Namespace):
    """
    Filters the TSV file containing the model's hypotheses for MuST-SHE based on gender coverage.
    Then generates a new version of these hypotheses with swapped gender, so the two versions
    can be compared when generating explanations.
    """
    # Load the hypotheses and MuST-SHE annotations and merge the two dataframes.
    df = pd.read_csv(args.hypotheses_tsv, sep='\t')
    df_mustshe = pd.read_csv(args.mustshe_tsv, sep='\t')
    # ids on both dataframes are slightly different
    df_mustshe['id'] = df_mustshe['ID'] + '_0'
    df = df.merge(df_mustshe[['id', 'GENDERTERMS']], on='id')
    df.rename(columns={'GENDERTERMS': 'gender_terms'}, inplace=True)

    # Get moses tokenized hypotheses to look for gender terms.
    sp = spm.SentencePieceProcessor(model_file=args.spm_model)
    df['moses_tgt_text'] = df['tgt_text'].apply(bpe_to_moses, args=(sp,))

    # Filter out gender terms which were not generated in the hypotheses.
    df[['found_terms', 'found_term_pairs']] = df.apply(
        filter_gender_terms, axis=1, result_type='expand')
    df = df[df.found_terms != '']

    # Find the indices of the remaining gender term tokens in the hypotheses.
    df['gender_terms_indices'] = df.apply(find_terms_bpe, args=(sp,), axis=1)

    # Repeat each row as many times as there are found terms.
    df['nb_found_terms'] = df['found_terms'].apply(lambda x: len(x.split(';') if x != '' else 0))
    df = df.loc[df.index.repeat(df.nb_found_terms)]
    df = df.reset_index(drop=True) # To avoid duplicate index values
    # Keep only one (different) gender term per row.
    df = one_term_per_row(df)    
        
    # Create a version of the hypotheses where the gender of the term is swapped.
    df['swapped_tgt_text'] = df.apply(swap_gender_hypothesis, args=(sp,), axis=1)    

    # Save the resulting tsv.
    df[OUTPUT_COLUMNS].to_csv(args.output_tsv, sep='\t', index=False)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description='Prepares a tsv file for explanation generation with hypotheses for MuST-SHE.')
    
    parser.add_argument('--hypotheses-tsv', type=str, required=True,
                        help='Path to a tsv file containing the model\'s hypotheses for MuST-SHE.')
    
    parser.add_argument('--mustshe-tsv', type=str, required=True,
                        help='Path to the original MuST-SHE tsv file with gender annotations.')
    
    parser.add_argument('--spm-model', type=str, required=True,
                        help='Path to the sentencepiece model used for BPE tokenization.')
    
    parser.add_argument('--output-tsv', type=str, required=True,
                        help='Path where to save the new filtered tsv with swapped gender.')
    
    parsed_args = parser.parse_args()
    main(parsed_args)
